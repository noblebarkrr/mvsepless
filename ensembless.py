import os
import tempfile
import gradio as gr

from model_list import models_data
from infer_utils.uvr_rename_stems import rename_stems
from infer_utils.audio_processing.invert import invert_and_overlay_wav
from multi_infer import audio_separation
from multi_infer import theme as mvsepless_theme
from ensem import ensemble_audio_files

from pydub import AudioSegment

# Econom ensemble (For large files and many models)
def econom_ensemble(files, output, ensemble_type, weights):
    """
    ĞŸĞ¾ÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ÑĞµÑ‚ ensemble_audio_files Ğº ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¼Ñƒ Ñ„Ğ°Ğ¹Ğ»Ñƒ Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ Ğ²ĞµÑĞ¾Ğ²
    """
    if len(files) != len(weights):
        raise ValueError("ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ¸ Ğ²ĞµÑĞ¾Ğ² Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ¾ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´Ğ°Ñ‚ÑŒ")
    
    temp_dir = tempfile.mkdtemp()
    current_output = None
    
    try:
        for i, (file, weight) in enumerate(zip(files, weights)):
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ» Ğ´Ğ»Ñ ÑÑ‚Ğ¾Ğ³Ğ¾ ÑˆĞ°Ğ³Ğ°
            temp_output = os.path.join(temp_dir, f"step_{i}.wav")
            
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¸Ğ· weight ĞºĞ¾Ğ¿Ğ¸Ğ¹ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ°
            weighted_files = [file] * int(weight)
            
            # ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ» - Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ ĞºĞ¾Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ (Ğ¸Ğ»Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ ĞµÑĞ»Ğ¸ weight > 1)
            if i == 0:
                if len(weighted_files) == 1:
                    import shutil
                    shutil.copyfile(file, temp_output)
                else:
                    ensemble_audio_files(
                        files=weighted_files,
                        output=temp_output,
                        ensemble_type=ensemble_type,
                        weights=None
                    )
            else:
                # Ğ”Ğ»Ñ Ğ¿Ğ¾ÑĞ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼ Ñ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ¼
                prev_file = os.path.join(temp_dir, f"step_{i-1}.wav")
                ensemble_files = weighted_files + [prev_file]
                
                ensemble_audio_files(
                    files=ensemble_files,
                    output=temp_output,
                    ensemble_type=ensemble_type,
                    weights=None
                )
                
                # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¹ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»
                if os.path.exists(prev_file):
                    os.remove(prev_file)
        
        # ĞŸĞµÑ€ĞµĞ¼ĞµÑ‰Ğ°ĞµĞ¼ Ñ„Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ² Ğ½ÑƒĞ¶Ğ½Ğ¾Ğµ Ğ¼ĞµÑÑ‚Ğ¾
        if temp_output and os.path.exists(temp_output):
            os.rename(temp_output, output)
            return output
        return None
    
    finally:
        # ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ
        if os.path.exists(temp_dir):
            for file in os.listdir(temp_dir):
                os.remove(os.path.join(temp_dir, file))
            os.rmdir(temp_dir)

# Resample audio for invert
def resample_for_invert(orig, result):
    filename = os.path.basename(orig)
    name_without_ext = os.path.splitext(filename)[0]
    folder_path = os.path.dirname(result)
    resampled_orig = f"{name_without_ext}_resampled.wav"
    audio1 = AudioSegment.from_file(orig)
    audio2 = AudioSegment.from_file(result)
    target_frame_rate = audio2.frame_rate
    audio1_resampled = audio1.set_frame_rate(target_frame_rate)
    audio1_resampled.export(resampled_orig, format="wav")
    return resampled_orig

# Ensemble_methods
ensemble_methods = ["min_wave", "median_wave", "avg_wave", "max_wave", "min_fft", "median_fft", "avg_fft", "max_fft"]

# Easy invert
def invert_result(result, orig):
    filename = os.path.basename(orig)
    name_without_ext = os.path.splitext(filename)[0]
    folder_path = os.path.dirname(result)
    inverted_file = os.path.join(folder_path, f"{name_without_ext}_inverted.wav")
    resampled_orig = resample_for_invert(orig, result)
    invert_and_overlay_wav(result, resampled_orig, inverted_file)
    return inverted_file

def get_model_options():
    options = []
    for model_type, model_dict in models_data.items():
        if model_type == "medley_vox":
            continue
        for model_name in model_dict:
            options.append(f"{model_type} / {model_name}")
    return options

def update_stems(model_label):
    try:
        model_type, model_name = model_label.split(" / ")
        return gr.update(choices=models_data[model_type][model_name]["stems"], value=[])
    except:
        return gr.update(choices=[], value=[])

# Ensemble process
def process(audio_path, method, use_econom, *inputs):
    temp_dir = tempfile.mkdtemp()
    try:
        file_name = os.path.splitext(os.path.basename(audio_path))[0]
        input_file_path = audio_path

        input_ensem_files = []
        block_count = (len(inputs) - 1) // 2
        weights = [float(w.strip()) for w in inputs[-1].split(",")]

        for i in range(block_count):
            model_label = inputs[i]
            stems = inputs[block_count + i]

            if not model_label or not stems:
                continue

            model_type, model_name = model_label.split(" / ")
            output_dir = os.path.join(temp_dir, file_name, f"{model_type}_{model_name}")
            os.makedirs(output_dir, exist_ok=True)

            audio_separation(
                input_dir=input_file_path,
                output_dir=output_dir,
                instrum=True,
                model_name=model_name,
                model_type=model_type,
                output_format="wav",
                use_tta=False,
                batch=False,
                template="MODEL_STEM",
                selected_instruments=[]
            )

            for stem in stems:
                if model_type in ["vr_arch", "mdx_net"]:
                    stem_filename = f"{model_name}_{stem}.wav"
                else:  
                    stem_filename = f"{model_type}_{model_name}_{stem}.wav"

                if not stem_filename:
                    continue

                stem_path = os.path.join(output_dir, stem_filename)
                if os.path.exists(stem_path):
                    input_ensem_files.append(stem_path)

        if not input_ensem_files:
            return None

        # --- Ğ”ĞĞŸĞĞ›ĞĞ•ĞĞ˜Ğ• ĞĞ£Ğ›Ğ¯ĞœĞ˜ Ğ”Ğ ĞĞ”Ğ˜ĞĞĞšĞĞ’ĞĞ™ Ğ”Ğ›Ğ˜ĞĞ« ---
        import soundfile as sf
        import numpy as np

        audio_data = []
        max_length = 0
        for file in input_ensem_files:
            data, sr = sf.read(file)
            if data.ndim == 1:
                data = np.stack([data, data])
            elif data.shape[0] != 2:
                data = data.T
            audio_data.append(data)
            if data.shape[1] > max_length:
                max_length = data.shape[1]

        padded_files = []
        for i, (data, file) in enumerate(zip(audio_data, input_ensem_files)):
            if data.shape[1] < max_length:
                pad_width = ((0, 0), (0, max_length - data.shape[1]))
                padded_data = np.pad(data, pad_width, mode='constant')
            else:
                padded_data = data

            output_padded_path = os.path.join(temp_dir, f"padded_{i}.wav")
            sf.write(output_padded_path, padded_data.T, sr)
            padded_files.append(output_padded_path)

        input_ensem_files = padded_files
        # --- ĞšĞĞĞ•Ğ¦ Ğ”ĞĞŸĞĞ›ĞĞ•ĞĞ˜Ğ¯ ---

        output_path = os.path.join(temp_dir, f"{file_name}_{method}_ensemble.wav")
        
        if use_econom:
            print("Econom Ensemble!")
            econom_ensemble(
                files=input_ensem_files,
                output=output_path,
                ensemble_type=method,
                weights=weights
            )
        else:
            ensemble_audio_files(
                files=input_ensem_files,
                output=output_path,
                ensemble_type=method,
                weights=weights
            )
            
        return output_path
    except Exception as e:
        print(f"ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
        return None

with gr.Blocks(theme=mvsepless_theme) as demo:
    gr.Markdown("# EnsembLess")

    audio = gr.Audio(label="Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ°ÑƒĞ´Ğ¸Ğ¾", type="filepath")
    method = gr.Dropdown(ensemble_methods, label="ĞœĞµÑ‚Ğ¾Ğ´", value="avg_wave")
    use_econom = gr.Checkbox(label="Ğ­ĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼ (Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ñ… Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²)", value=False)
    weights = gr.Textbox(label="Ğ’ĞµÑĞ¾Ğ²Ñ‹Ğµ ĞºĞ¾ÑÑ„Ñ„Ğ¸Ñ†Ğ¸ĞµĞ½Ñ‚Ñ‹ (Ñ‡ĞµÑ€ĞµĞ· Ğ·Ğ°Ğ¿ÑÑ‚ÑƒÑ)", value="1.0,1.0")
    output_audio = gr.Audio(label="Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚", interactive=False, type="filepath")
    invert_btn = gr.Button("Ğ˜Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚")
    inverted_output = gr.Audio(label="Ğ˜Ğ½Ğ²ĞµÑ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚", interactive=False, type="filepath")
    invert_btn.click(
        fn=invert_result,
        inputs=[output_audio, audio],
        outputs=[inverted_output]
    )

    model_blocks = []
    model_dropdowns = []
    stem_dropdowns = []

    used_blocks = gr.State(value=[True, True] + [False] * 8)

    for i in range(10):
        with gr.Row(visible=(i < 2)) as row:
            model_dd = gr.Dropdown(get_model_options(), label="Ğ¢Ğ¸Ğ¿ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ / Ğ˜Ğ¼Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸", interactive=True)
            stem_dd = gr.Dropdown(choices=[], multiselect=True, label="Ğ¡Ñ‚ĞµĞ¼Ñ‹", interactive=True)
            remove_btn = gr.Button("ğŸ—‘ï¸", size="sm")

            model_dd.change(fn=update_stems, inputs=model_dd, outputs=stem_dd)

            def make_remove_fn(index):
                def remove(used):
                    used[index] = False
                    return (
                        gr.update(value=used),
                        gr.update(visible=False), gr.update(value=None),
                        gr.update(visible=False), gr.update(value=None)
                    )
                return remove

            remove_btn.click(
                fn=make_remove_fn(i),
                inputs=[used_blocks],
                outputs=[used_blocks, row, model_dd, stem_dd]
            )

            model_blocks.append((row, model_dd, stem_dd))
            model_dropdowns.append(model_dd)
            stem_dropdowns.append(stem_dd)

    def show_next_block(used):
        for i, is_used in enumerate(used):
            if not is_used:
                used[i] = True
                updates = [gr.update(value=used)]
                for j, (row, model_dd, stem_dd) in enumerate(model_blocks):
                    updates.extend([
                        gr.update(visible=used[j]),
                        gr.update(visible=used[j]),
                        gr.update(visible=used[j])
                    ])
                return updates
        return [gr.update()] * (1 + 3 * 10)

    add_button = gr.Button("+")
    add_button.click(
        fn=show_next_block,
        inputs=[used_blocks],
        outputs=[used_blocks] + sum([[row, model_dd, stem_dd] for (row, model_dd, stem_dd) in model_blocks], [])
    )

    run_btn = gr.Button("Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ°Ğ½ÑĞ°Ğ¼Ğ±Ğ»ÑŒ")
    run_btn.click(
        fn=process,
        inputs=[audio, method, use_econom, *model_dropdowns, *stem_dropdowns, weights],
        outputs=[output_audio]
    )

demo.launch(share=True)